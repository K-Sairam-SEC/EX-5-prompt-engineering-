# Ex. No. 5 – Comparative Analysis of Naïve Prompting versus Basic Prompting Using ChatGPT Across Various Test Scenarios

### Date: 21/10/2025
### Register No.: 25000527

# Aim:

To test how ChatGPT responds to naïve prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios, and to analyze the quality, accuracy, and depth of the generated responses.

# Algorithm:

Define Prompt Types:

Naïve Prompts: Vague, open-ended, or lacking context.

Basic Prompts: Clear, structured, and detailed with explicit instructions.

Prepare Test Scenarios:
Five different scenarios were selected to evaluate prompt effectiveness:

Creative storytelling

Factual question answering

Concept summarization

Advice or recommendation

Technical explanation

Create Prompt Pairs:
For each scenario, one naïve and one basic prompt were created to perform the same task.

Run Experiments:

The naïve prompt was input into ChatGPT, and its response was recorded.

The basic prompt was then input for comparison.

Evaluate Responses:

Each response was assessed on quality, accuracy, and depth.

Observations were made on how the prompt’s clarity affected output performance.

Analyze Results:

Compare outputs from both prompt types.

Determine whether refined prompts produce better, more useful results.

Procedure:

Opened ChatGPT and prepared a test environment for consistent evaluation.

Entered a set of naïve prompts representing minimal input guidance.

Entered corresponding basic prompts with more context, instructions, or structure.

Recorded both responses in a comparison table.

Evaluated each pair according to three metrics — quality, accuracy, and depth.

Compiled results into a summarized analysis table.

+------------------------+---------------------------+-----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------------+-------------+-------------+-------------+
| Scenario               | Naïve Prompt              | ChatGPT Response (Naïve)                      | Basic Prompt                                                             | ChatGPT Response (Basic)                                             | Quality     | Accuracy    | Depth       |
+------------------------+---------------------------+-----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------------+-------------+-------------+-------------+
| Creative Story         | Tell me a story.          | Simple, generic story about a boy and his dog.| Write a 300-word fantasy story about a brave girl fighting a dragon.     | Detailed fantasy story with strong structure and emotional depth.     | Basic > N   | Basic > N   | Basic > N   |
| Factual Q&A            | Tell me about Mars.       | Short, general description of the planet.     | List five key facts about Mars’ atmosphere and surface conditions.       | Accurate, fact-rich answer with organized points.                     | Basic > N   | Basic > N   | Basic > N   |
| Concept Summarization  | Summarize photosynthesis. | Over-simplified explanation.                  | Summarize the process of photosynthesis in 3–4 lines for students.       | Clear, concise, and scientifically accurate summary.                  | Basic > N   | Basic > N   | Basic > N   |
| Advice/Recommendation  | Give me some advice.      | Generic motivational advice.                  | Give 3 productivity tips for college students managing time.             | Specific and actionable suggestions.                                  | Basic > N   | Basic > N   | Basic > N   |
| Technical Explanation  | Explain AI.               | Broad, general explanation of AI.             | Explain artificial intelligence in simple terms for a 12-year-old.       | Clear, engaging explanation with relatable examples.                  | Basic > N   | Basic > N   | Basic > N   |
+------------------------+---------------------------+-----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------------------------+-------------+-------------+-------------+


Across all five scenarios, basic prompts produced significantly better responses in clarity, relevance, and depth.

Naïve prompts resulted in vague or repetitive answers lacking direction.

Providing explicit details or constraints improved factual precision and creativity.

The model performed best when given structured guidance (e.g., tone, length, or target audience).

This demonstrates that prompt engineering directly influences output quality.

Conclusion:

Basic prompting consistently outperforms naïve prompting in terms of response quality, factual accuracy, and contextual depth.

Well-crafted prompts enable ChatGPT to interpret intent more effectively and produce more meaningful results.

No test case showed naïve prompting performing equal to or better than basic prompting.

Therefore, clear and structured prompt design is essential for maximizing the potential of conversational AI models.

Result:

The prompt for the above-said problem executed successfully, and the comparative analysis confirmed that refined prompting yields superior AI responses across diverse test scenarios.
